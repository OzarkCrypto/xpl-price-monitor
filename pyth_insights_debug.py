#!/usr/bin/env python3
"""
PYTH Insights ë””ë²„ê·¸ - ì‹¤ì œ HTML êµ¬ì¡° ë¶„ì„
"""

import requests
import json
import re

def debug_insights_page():
    """PYTH Insights í˜ì´ì§€ì˜ ì‹¤ì œ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1'
    })
    
    url = "https://insights.pyth.network/publishers?page=1"
    
    try:
        print("ğŸ” PYTH Insights í˜ì´ì§€ ë¶„ì„ ì¤‘...")
        response = session.get(url, timeout=15)
        
        if response.status_code == 200:
            html_content = response.text
            
            print(f"âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ (í¬ê¸°: {len(html_content)} bytes)")
            
            # 1. í˜ì´ì§€ ì œëª© í™•ì¸
            title_match = re.search(r'<title[^>]*>(.*?)</title>', html_content, re.IGNORECASE)
            if title_match:
                print(f"ğŸ“„ í˜ì´ì§€ ì œëª©: {title_match.group(1)}")
            
            # 2. ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ ë¶„ì„
            script_tags = re.findall(r'<script[^>]*>(.*?)</script>', html_content, re.DOTALL | re.IGNORECASE)
            print(f"ğŸ“œ ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ ìˆ˜: {len(script_tags)}")
            
            # 3. JSON ë°ì´í„°ê°€ í¬í•¨ëœ ìŠ¤í¬ë¦½íŠ¸ ì°¾ê¸°
            json_scripts = []
            for i, script in enumerate(script_tags):
                if any(keyword in script.lower() for keyword in ['publisher', 'ranking', 'active', 'permissioned', 'score']):
                    json_scripts.append((i, script))
            
            print(f"ğŸ” í¼ë¸”ë¦¬ì…” ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸: {len(json_scripts)}ê°œ")
            
            # 4. í…Œì´ë¸” êµ¬ì¡° ë¶„ì„
            table_pattern = r'<table[^>]*>(.*?)</table>'
            tables = re.findall(table_pattern, html_content, re.DOTALL | re.IGNORECASE)
            print(f"ğŸ“Š í…Œì´ë¸” ìˆ˜: {len(tables)}")
            
            # 5. Loading í…ìŠ¤íŠ¸ í™•ì¸
            loading_count = html_content.lower().count('loading')
            print(f"â³ 'Loading' í…ìŠ¤íŠ¸ ìˆ˜: {loading_count}")
            
            # 6. React ê´€ë ¨ ì •ë³´ í™•ì¸
            react_keywords = ['react', 'next', 'vue', 'angular', 'spa']
            for keyword in react_keywords:
                count = html_content.lower().count(keyword)
                if count > 0:
                    print(f"âš›ï¸  '{keyword}' í‚¤ì›Œë“œ: {count}ê°œ")
            
            # 7. API í˜¸ì¶œ íŒ¨í„´ ì°¾ê¸°
            api_patterns = [
                r'fetch\(["\']([^"\']*publisher[^"\']*)["\']',
                r'axios\.get\(["\']([^"\']*publisher[^"\']*)["\']',
                r'api/publishers',
                r'/api/',
                r'graphql'
            ]
            
            for pattern in api_patterns:
                matches = re.findall(pattern, html_content, re.IGNORECASE)
                if matches:
                    print(f"ğŸ”— API íŒ¨í„´ '{pattern}' ë°œê²¬: {matches[:3]}")  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
            
            # 8. ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            data_keywords = ['72', 'publishers', 'ranking', 'active', 'permissioned']
            for keyword in data_keywords:
                count = html_content.count(keyword)
                if count > 0:
                    print(f"ğŸ“Š '{keyword}' í‚¤ì›Œë“œ: {count}ê°œ")
            
            # 9. HTML êµ¬ì¡° ì €ì¥
            with open('pyth_insights_debug.html', 'w', encoding='utf-8') as f:
                f.write(html_content)
            print("ğŸ“„ HTML êµ¬ì¡°ê°€ 'pyth_insights_debug.html'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # 10. ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            print("\n=== í˜ì´ì§€ì—ì„œ ë°œê²¬ëœ ì£¼ìš” í…ìŠ¤íŠ¸ ===")
            lines = html_content.split('\n')
            for line in lines:
                line = line.strip()
                if any(keyword in line.lower() for keyword in ['publisher', '72', 'active', 'ranking', 'permissioned']):
                    if len(line) < 200:  # ë„ˆë¬´ ê¸´ ë¼ì¸ì€ ì œì™¸
                        print(f"  {line}")
            
            return html_content
        else:
            print(f"âŒ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
            return None
            
    except Exception as e:
        print(f"ğŸ’¥ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def analyze_network_requests():
    """ë„¤íŠ¸ì›Œí¬ ìš”ì²­ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    print("\nğŸ” ë„¤íŠ¸ì›Œí¬ ìš”ì²­ íŒ¨í„´ ë¶„ì„...")
    
    # ì¼ë°˜ì ì¸ API ì—”ë“œí¬ì¸íŠ¸ë“¤ ì‹œë„
    base_url = "https://insights.pyth.network"
    endpoints = [
        "/api/publishers",
        "/api/v1/publishers", 
        "/api/v2/publishers",
        "/api/data/publishers",
        "/api/insights/publishers",
        "/api/stats/publishers",
        "/graphql",
        "/api/graphql",
        "/_next/data/publishers",
        "/_next/static/chunks/publishers"
    ]
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        'Accept': 'application/json, text/plain, */*',
        'Referer': 'https://insights.pyth.network/publishers'
    })
    
    for endpoint in endpoints:
        url = f"{base_url}{endpoint}"
        try:
            response = session.get(url, timeout=10)
            print(f"  {endpoint}: {response.status_code} ({len(response.text)} bytes)")
            
            if response.status_code == 200 and len(response.text) > 100:
                # JSON ì‘ë‹µì¸ì§€ í™•ì¸
                try:
                    data = response.json()
                    if isinstance(data, dict) or isinstance(data, list):
                        print(f"    âœ… JSON ì‘ë‹µ ë°œê²¬!")
                        # ë°ì´í„° êµ¬ì¡° í™•ì¸
                        if isinstance(data, dict):
                            print(f"    ğŸ“Š í‚¤: {list(data.keys())[:5]}")
                        elif isinstance(data, list) and data:
                            print(f"    ğŸ“Š ì²« ë²ˆì§¸ í•­ëª©: {list(data[0].keys())[:5] if isinstance(data[0], dict) else 'not dict'}")
                except json.JSONDecodeError:
                    pass
                    
        except Exception as e:
            print(f"  {endpoint}: ì—°ê²° ì‹¤íŒ¨ - {e}")

def main():
    print("ğŸš€ PYTH Insights ë””ë²„ê·¸ ì‹œì‘...\n")
    
    # 1. í˜ì´ì§€ êµ¬ì¡° ë¶„ì„
    html_content = debug_insights_page()
    
    # 2. ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„
    analyze_network_requests()
    
    print("\nâœ… ë””ë²„ê·¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 