#!/usr/bin/env python3
"""
PYTH Insights í¼ë¸”ë¦¬ì…” ì •ë³´ ê°€ì ¸ì˜¤ê¸°
https://insights.pyth.network/publishers ì—ì„œ ì‹¤ì œ í¼ë¸”ë¦¬ì…” ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
"""

import requests
import json
import time
from typing import Dict, List, Optional

class PythInsightsPublisherFetcher:
    def __init__(self):
        self.base_url = "https://insights.pyth.network"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://insights.pyth.network/',
            'Origin': 'https://insights.pyth.network'
        })
    
    def get_publishers_api_endpoint(self) -> Optional[str]:
        """PYTH Insightsì˜ í¼ë¸”ë¦¬ì…” API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        print("ğŸ” PYTH Insights API ì—”ë“œí¬ì¸íŠ¸ ì°¾ëŠ” ì¤‘...")
        
        # ê°€ëŠ¥í•œ API ì—”ë“œí¬ì¸íŠ¸ë“¤
        possible_endpoints = [
            "/api/publishers",
            "/api/v1/publishers", 
            "/api/v2/publishers",
            "/api/publishers/list",
            "/api/publishers/active",
            "/api/publishers/all",
            "/api/publishers/ranking",
            "/api/publishers/stats",
            "/api/publishers/details",
            "/api/publishers/metadata",
            "/api/publishers/summary",
            "/api/publishers/overview",
            "/api/publishers/feed",
            "/api/publishers/data",
            "/api/publishers/info"
        ]
        
        for endpoint in possible_endpoints:
            url = f"{self.base_url}{endpoint}"
            try:
                response = self.session.get(url, timeout=10)
                print(f"  í…ŒìŠ¤íŠ¸: {endpoint} - {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        if self._is_publisher_data(data):
                            print(f"  âœ… í¼ë¸”ë¦¬ì…” ë°ì´í„° ë°œê²¬: {endpoint}")
                            return endpoint
                    except json.JSONDecodeError:
                        pass
                        
            except requests.exceptions.RequestException as e:
                print(f"  âŒ ì—°ê²° ì‹¤íŒ¨: {endpoint} - {e}")
        
        return None
    
    def _is_publisher_data(self, data) -> bool:
        """ë°ì´í„°ê°€ í¼ë¸”ë¦¬ì…” ì •ë³´ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        if isinstance(data, dict):
            # í¼ë¸”ë¦¬ì…” ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
            publisher_keywords = ['publishers', 'publisher', 'ranking', 'active', 'permissioned', 'score']
            for key in data.keys():
                if any(keyword in key.lower() for keyword in publisher_keywords):
                    return True
            
            # ê°’ì—ì„œë„ í™•ì¸
            for value in data.values():
                if self._is_publisher_data(value):
                    return True
                    
        elif isinstance(data, list):
            # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ í•­ëª©ì´ í¼ë¸”ë¦¬ì…” ì •ë³´ì¸ì§€ í™•ì¸
            if data and isinstance(data[0], dict):
                first_item = data[0]
                publisher_fields = ['name', 'id', 'ranking', 'active', 'permissioned', 'score']
                if any(field in first_item for field in publisher_fields):
                    return True
        
        return False
    
    def get_publishers_from_insights(self) -> Dict:
        """PYTH Insightsì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        print("ğŸ“Š PYTH Insightsì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        # 1. API ì—”ë“œí¬ì¸íŠ¸ ì°¾ê¸°
        api_endpoint = self.get_publishers_api_endpoint()
        
        if api_endpoint:
            return self._fetch_from_api(api_endpoint)
        else:
            print("âš ï¸  API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹í˜ì´ì§€ íŒŒì‹±ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            return self._parse_webpage()
    
    def _fetch_from_api(self, endpoint: str) -> Dict:
        """APIì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        url = f"{self.base_url}{endpoint}"
        
        try:
            response = self.session.get(url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                return self._process_publisher_data(data)
            else:
                print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status_code}")
                return {}
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ API ì—°ê²° ì‹¤íŒ¨: {e}")
            return {}
    
    def _parse_webpage(self) -> Dict:
        """ì›¹í˜ì´ì§€ì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        print("ğŸŒ ì›¹í˜ì´ì§€ íŒŒì‹± ì‹œë„ ì¤‘...")
        
        # ì—¬ëŸ¬ í˜ì´ì§€ ì‹œë„
        publishers_data = []
        
        for page in range(1, 10):  # ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€ ì‹œë„
            url = f"{self.base_url}/publishers?page={page}"
            
            try:
                response = self.session.get(url, timeout=10)
                if response.status_code == 200:
                    print(f"  ğŸ“„ í˜ì´ì§€ {page} ë¡œë“œ ì„±ê³µ")
                    
                    # í˜ì´ì§€ì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ ì¶”ì¶œ ì‹œë„
                    page_data = self._extract_publishers_from_html(response.text)
                    if page_data:
                        publishers_data.extend(page_data)
                        print(f"  âœ… í˜ì´ì§€ {page}ì—ì„œ {len(page_data)}ê°œ í¼ë¸”ë¦¬ì…” ë°œê²¬")
                    else:
                        print(f"  âš ï¸  í˜ì´ì§€ {page}ì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ ì—†ìŒ")
                        break  # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                else:
                    print(f"  âŒ í˜ì´ì§€ {page} ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
                    break
                    
            except requests.exceptions.RequestException as e:
                print(f"  ğŸ’¥ í˜ì´ì§€ {page} ì—°ê²° ì‹¤íŒ¨: {e}")
                break
            
            time.sleep(1)  # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
        
        return {
            'publishers': publishers_data,
            'total_count': len(publishers_data),
            'source': 'webpage_parsing'
        }
    
    def _extract_publishers_from_html(self, html_content: str) -> List[Dict]:
        """HTMLì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        publishers = []
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹±ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        lines = html_content.split('\n')
        
        for line in lines:
            # í¼ë¸”ë¦¬ì…” ê´€ë ¨ ì •ë³´ê°€ í¬í•¨ëœ ë¼ì¸ ì°¾ê¸°
            if any(keyword in line.lower() for keyword in ['publisher', 'ranking', 'active', 'permissioned']):
                # JSON í˜•íƒœì˜ ë°ì´í„° ì°¾ê¸°
                if '{' in line and '}' in line:
                    try:
                        # JSON ë¶€ë¶„ ì¶”ì¶œ
                        start = line.find('{')
                        end = line.rfind('}') + 1
                        json_str = line[start:end]
                        data = json.loads(json_str)
                        
                        if self._is_publisher_data(data):
                            if isinstance(data, list):
                                publishers.extend(data)
                            else:
                                publishers.append(data)
                                
                    except json.JSONDecodeError:
                        pass
        
        return publishers
    
    def _process_publisher_data(self, data) -> Dict:
        """í¼ë¸”ë¦¬ì…” ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        if isinstance(data, dict):
            # í†µê³„ ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš°
            if 'publishers' in data:
                publishers = data['publishers']
            elif 'data' in data:
                publishers = data['data']
            else:
                publishers = data
                
        elif isinstance(data, list):
            publishers = data
        else:
            publishers = []
        
        # í¼ë¸”ë¦¬ì…” ì •ë³´ ì •ë¦¬
        processed_publishers = []
        
        for pub in publishers:
            if isinstance(pub, dict):
                processed_pub = {
                    'name': pub.get('name', pub.get('id', 'Unknown')),
                    'id': pub.get('id', pub.get('publisher_id', 'Unknown')),
                    'ranking': pub.get('ranking', pub.get('rank', 0)),
                    'active_feeds': pub.get('active', pub.get('active_feeds', 0)),
                    'permissioned_feeds': pub.get('permissioned', pub.get('permissioned_feeds', 0)),
                    'average_score': pub.get('average_score', pub.get('score', 0)),
                    'cluster': pub.get('cluster', 'Unknown'),
                    'status': pub.get('status', 'active')
                }
                processed_publishers.append(processed_pub)
        
        return {
            'publishers': processed_publishers,
            'total_count': len(processed_publishers),
            'source': 'api',
            'raw_data': data
        }
    
    def save_results(self, data: Dict, filename: str = "pyth_insights_publishers.json"):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # CSVë¡œë„ ì €ì¥
        if data.get('publishers'):
            csv_filename = filename.replace('.json', '.csv')
            import csv
            
            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Ranking', 'Name', 'ID', 'Active Feeds', 'Permissioned Feeds', 'Average Score', 'Cluster', 'Status'])
                
                for pub in data['publishers']:
                    writer.writerow([
                        pub.get('ranking', ''),
                        pub.get('name', ''),
                        pub.get('id', ''),
                        pub.get('active_feeds', ''),
                        pub.get('permissioned_feeds', ''),
                        pub.get('average_score', ''),
                        pub.get('cluster', ''),
                        pub.get('status', '')
                    ])
            
            print(f"ğŸ“Š CSV íŒŒì¼ë„ {csv_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def print_summary(self, data: Dict):
        """ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
        print("\n=== PYTH Insights í¼ë¸”ë¦¬ì…” ì •ë³´ ìš”ì•½ ===")
        
        if data.get('publishers'):
            publishers = data['publishers']
            total_count = data.get('total_count', len(publishers))
            source = data.get('source', 'unknown')
            
            print(f"ğŸ“Š ì´ í¼ë¸”ë¦¬ì…” ìˆ˜: {total_count}")
            print(f"ğŸ”— ë°ì´í„° ì†ŒìŠ¤: {source}")
            print(f"ğŸ“… ê²€ìƒ‰ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            
            print(f"\n=== ìƒìœ„ 10ê°œ í¼ë¸”ë¦¬ì…” ===")
            sorted_publishers = sorted(publishers, key=lambda x: x.get('ranking', 999))
            
            for i, pub in enumerate(sorted_publishers[:10]):
                print(f"{i+1:2d}. {pub.get('name', 'Unknown')} (Rank: {pub.get('ranking', 'N/A')})")
                print(f"    Active: {pub.get('active_feeds', 0)}, Permissioned: {pub.get('permissioned_feeds', 0)}")
                print(f"    Score: {pub.get('average_score', 0):.2f}, Cluster: {pub.get('cluster', 'Unknown')}")
                print()
        else:
            print("âŒ í¼ë¸”ë¦¬ì…” ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def main():
    fetcher = PythInsightsPublisherFetcher()
    
    # PYTH Insightsì—ì„œ í¼ë¸”ë¦¬ì…” ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    publishers_data = fetcher.get_publishers_from_insights()
    
    # ê²°ê³¼ ì¶œë ¥
    fetcher.print_summary(publishers_data)
    
    # ê²°ê³¼ ì €ì¥
    if publishers_data.get('publishers'):
        fetcher.save_results(publishers_data)
    else:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 